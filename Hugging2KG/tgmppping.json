{
    "architecture:vits": "architecture:VITS",
    "architecture:vit": "architecture:ViT",
    "architecture:vision_transformer": "architecture:Vision Transformer",
    "architecture:vision-transformer": "architecture:Vision Transformer",
    "architecture:diffusion_model": "architecture:diffusion-model",
    "architecture:latent_diffusion_model": "architecture:latent-diffusion-model",
    "architecture:stable-diffusion": "architecture:Stable Diffusion",
    "architecture:stable-diffusion-xl": "architecture:stable-diffusion-xl",
    "architecture:yolov8": "architecture:YOLOv8",
    "architecture:yolov5": "architecture:YOLOv5",
    "architecture:detr-resnet-50": "architecture:detr-resnet50",
    "architecture:segformer-b0": "architecture:segformer-b0",
    "architecture:segformer": "architecture:Segformer",
    "architecture:efficientnet": "architecture:EfficientNet",
    "architecture:convnext": "architecture:ConvNeXt",
    "architecture:swin_transformer": "architecture:Swin Transformer",
    "architecture:swin-transformer": "architecture:Swin Transformer",
    "architecture:mobilenet_v2": "architecture:MobileNetV2",
    "architecture:mobilenet-v3": "architecture:MobileNetV3",
    "architecture:convtasnet": "architecture:ConvTasNet",
    "architecture:ddpm": "architecture:DDPM",
    "architecture:longformer": "architecture:Longformer",
    "architecture:distilhubert": "architecture:DistilHuBERT",
    "architecture:yolos": "architecture:YOLOS",
    "architecture:detr": "architecture:DETR",
    "architecture:resnet": "architecture:ResNet",
    "architecture:convnextv2": "architecture:ConvNeXt V2",
    "architecture:timesformer": "architecture:TimeSformer",
    "architecture:xlm-roberta": "architecture:XLM-RoBERTa",
    "architecture:deberta": "architecture:DeBERTa",
    "architecture:deberta-v3": "architecture:DeBERTa-v3",
    "architecture:deberta-v2": "architecture:DeBERTa-v2",
    "architecture:visionencoderdecodermodel": "architecture:VisionEncoderDecoderModel",
    "architecture:bert-base-uncased": "architecture:bert-base-uncased",
    "architecture:setfit": "architecture:SetFit",
    "architecture:distilroberta": "architecture:DistilRoBERTa",
    "architecture:mpnet": "architecture:MPNet",
    "architecture:cross-encoder": "architecture:CrossEncoder",
    "architecture:bert-large": "architecture:BERT-Large",
    "architecture:lstm-crf": "architecture:LSTM-CRF",
    "architecture:autoencoder": "architecture:Autoencoder",
    "architecture:seq2seq": "architecture:Seq2Seq",
    "architecture:mobilebert": "architecture:MobileBERT",
    "architecture:mdeberta-v3-base": "architecture:mDeBERTa-v3-base",
    "architecture:mdeberta-v3": "architecture:mDeBERTa-v3",
    "architecture:deberta-v3-large": "architecture:deberta-v3-large",
    "architecture:deberta-v3-base": "architecture:deberta-v3-base",
    "architecture:setfit_with_sentence_transformer": "architecture:setfit-with-sentence-transformer",
    "architecture:bert-base": "architecture:BERT-Base",
    "architecture:marianmt": "architecture:MarianMT",
    "task_type:sentiment_analysis": "task_type:sentiment-analysis",
    "modality:text_to_speech": "modality:text-to-speech",
    "task_type:masked_language_modeling": "task_type:masked-language-modeling",
    "task_type:speech_recognition": "task_type:speech-recognition",
    "modality:speech_to_text": "modality:speech-to-text",
    "modality:audio_to_text": "modality:audio-to-text",
    "task_type:text_classification": "task_type:text-classification",
    "task_type:text_generation": "task_type:text-generation",
    "task_type:text2text-generation": "task_type:text2text-generation",
    "task_type:text-to-text": "task_type:text-to-text-generation",
    "task_type:text-to-text-generation": "task_type:text2text-generation",
    "task_type:zero-shot-classification": "task_type:zero-shot-classification",
    "task_type:depth_estimation": "task_type:depth-estimation",
    "task_type:object_detection": "task_type:object-detection",
    "task_type:question_answering": "task_type:question-answering",
    "task_type:video-classification": "task_type:video-classification",
    "task_type:named_entity_recognition": "task_type:named-entity-recognition",
    "task_type:image_classification": "task_type:image-classification",
    "task_type:image_segmentation": "task_type:image-segmentation",
    "task_type:image_generation": "task_type:image-generation",
    "task_type:audio-classification": "task_type:audio-classification",
    "task_type:audio-to-audio": "task_type:audio-to-audio",
    "modality:image_to_text": "modality:image-to-text",
    "modality:image_to_image": "modality:image-to-image",
    "modality:text_to_image": "modality:text-to-image",
    "modality:text_to_video": "modality:text-to-video",
    "modality:text_and_image": "modality:text-and-image",
    "modality:text_and_audio": "modality:text-and-audio",
    "modality:audio_text": "modality:audio-text",
    "hardware_needs:cuda": "hardware_needs:CUDA",
    "hardware_needs:a100": "hardware_needs:A100",
    "hardware_needs:a100_gpu": "hardware_needs:A100 GPU",
    "dataset:squad_v2": "dataset:squad2",
    "dataset:squad2.0": "dataset:squad2",
    "dataset:cnn_dailymail": "dataset:cnn_dailymail",
    "dataset:imagenet-21k": "dataset:imagenet-21k",
    "dataset:imagenet-22k": "dataset:imagenet-22k",
    "dataset:imagenet": "dataset:ImageNet",
    "dataset:common_voice": "dataset:Common Voice",
    "dataset:librispeech_asr": "dataset:librispeech_asr",
    "quantization:bfloat16": "quantization:BFLOAT16",
    "quantization:int8": "quantization:INT8",
    "quantization:fp16": "quantization:FP16"
}